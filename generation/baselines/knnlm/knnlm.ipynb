{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# from generation.baselines.knnlm._junk.knnlm_without_adacad import KNNLM\n",
    "# from generation.baselines.knnlm.knnlm_faiss import KNNLM as KNNLMFaiss\n",
    "from generation.baselines.knnlm.knnlm import KNNLM\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "\n",
    "print(f\"Python Version : {sys.version}\")\n",
    "print(f\"Torch Version : {torch.__version__}\")\n",
    "print(f\"Transformers Version : {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slack_notifier import send_slack_notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "set_seed(1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knnlm_model = KNNLMFaiss(model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", device=2)\n",
    "# knnlm_model = KNNLM(model_name=\"Equall/Saul-7B-Instruct-v1\", device=3)\n",
    "knnlm_model = KNNLM(model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", device=3)\n",
    "# knnlmada_model = KNNLM(model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", device=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from generation.workshop.dataloader import ModelInputPreprocessor\n",
    "from generation.workshop.experiment_utils import (\n",
    "    evaluate, \n",
    "    )\n",
    "\n",
    "data_dir = \"bm25_oracle_passages_oracle_documents\"\n",
    "\n",
    "preprocessor = ModelInputPreprocessor(\n",
    "    tokenizer=knnlm_model.tokenizer,\n",
    ")\n",
    "config = {\n",
    "    \"dataset_percentage\": 0.005,\n",
    "    \"dataset\": \"echr_qa\",\n",
    "    \"method\": \"cad\",\n",
    "    \"setup\": data_dir,\n",
    "    \"split\": \"test\",\n",
    "    \"top_k_passages\": 3,\n",
    "    \"max_tokens\": knnlm_model.model.config.max_position_embeddings,\n",
    "    \"use_instructions\": True,\n",
    "}\n",
    "work_dataset = preprocessor.process_dataset(config)\n",
    "\n",
    "new_record_processed = work_dataset[0]\n",
    "print(json.dumps(new_record_processed, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    f\"{new_record_processed['context_prefix']}\\n\\n{new_record_processed['context']}\",\n",
    "]\n",
    "\n",
    "prompts = [\n",
    "    new_record_processed[\"prompt\"],\n",
    "]\n",
    "\n",
    "references = [\n",
    "    new_record_processed[\"meta.oracle_documents\"],\n",
    "]\n",
    "\n",
    "max_length = 200\n",
    "decoding_strategy = 'greedy'\n",
    "use_repetition_penalty = True\n",
    "repetition_penalty_value = 1.5\n",
    "k = 10\n",
    "strategy = 'entropy'\n",
    "lamba = 1.0\n",
    "temperature = 1.0\n",
    "# variant = \"context\"\n",
    "variant = \"context_plus\"\n",
    "entropy_strategy='exp_norm'\n",
    "entropy_sigmoid_threshold=0.0\n",
    "lambda_smoothing_factor=0.45\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            prompts=prompts,\n",
    "                            contexts=contexts,\n",
    "                            references=references,\n",
    "                            max_length=max_length,\n",
    "                            decoding_strategy=decoding_strategy,\n",
    "                            k=k,\n",
    "                            strategy=strategy,\n",
    "                            lamba=lamba,\n",
    "                            variant=variant,\n",
    "                            entropy_strategy=entropy_strategy, \n",
    "                            entropy_sigmoid_threshold=entropy_sigmoid_threshold,\n",
    "                            lambda_smoothing_factor=lambda_smoothing_factor,\n",
    "                            use_repetition_penalty=use_repetition_penalty,\n",
    "                            repetition_penalty_value=repetition_penalty_value,\n",
    "                            datastore_from_layer_index=-1,\n",
    "                            temperature=temperature\n",
    "                            )\n",
    "decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "for i, output in enumerate(decoded_output):\n",
    "    print(f\"Output {i}: {output}\")\n",
    "    results = {}\n",
    "    results['meta'] = {}\n",
    "    results['meta']['docid'] = new_record_processed['docid']\n",
    "    results['meta']['previous_text'] = new_record_processed['meta.previous_text']\n",
    "    results['meta']['gold_text'] = new_record_processed['meta.gold_text']\n",
    "    results['gen'] = output\n",
    "    scores = evaluate([results], 3, work_dataset, \"knnlm\")\n",
    "    print(json.dumps(scores, indent=4))\n",
    "    print(f\"=====================================\")\n",
    "# The case at hand involves a claimant, Merle Fowler, who is disabled due to multiple sclerosis. The Social Security Administration (SSA) initially denied her disability benefits, citing difficulties in establishing an onset date and the loss or destruction of critical records related to her first application for benefits. However, upon reviewing the case, the court finds that the SSA's determination that no disability existed on June 30, 1966, is not supported by the evidence.\n",
    "\n",
    "# The claimant worked for various medical schools from the 1950s until 1967, when her condition became increasingly severe. During this period, she experienced physical disabilities such as problems maintaining balance, slurred speech, difficulty typing, and extended periods of rest. Despite these difficulties, she continued to work due to her need for self-support. In 1967, her condition worsened to the point where\n",
    "        # \"correctness\": 36.0,\n",
    "        # \"faithfulness\": {\n",
    "        #     \"documents\": 31.07,\n",
    "        #     \"passages\": 56.07\n",
    "        # }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    # new_record_processed[\"meta\"][\"oracle_documents\"],\n",
    "    new_record_processed[\"meta\"][\"oracle_documents\"],\n",
    "]\n",
    "\n",
    "prompts = [\n",
    "    # new_record_processed[\"prompt\"],\n",
    "    f\"{new_record_processed['context_prefix']}\\n\\n{new_record_processed['context']}{knnlm_model.tokenizer.eos_token}{new_record_processed['prompt']}\",\n",
    "]\n",
    "\n",
    "\n",
    "max_length = 200\n",
    "decoding_strategy = 'greedy'\n",
    "use_repetition_penalty = True\n",
    "repetition_penalty_value = 2.0\n",
    "k = 10\n",
    "strategy = 'entropy'\n",
    "lamba = 0.5\n",
    "temperature = 1.0\n",
    "variant = \"plus\"\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            prompts=prompts,\n",
    "                            contexts=contexts,\n",
    "                            max_length=max_length,\n",
    "                            decoding_strategy=decoding_strategy,\n",
    "                            k=k,\n",
    "                            strategy=strategy,\n",
    "                            lamba=lamba,\n",
    "                            variant=variant,\n",
    "                            use_repetition_penalty=use_repetition_penalty,\n",
    "                            repetition_penalty_value=repetition_penalty_value,\n",
    "                            datastore_from_layer_index=-1,\n",
    "                            temperature=temperature\n",
    "                            )\n",
    "decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(f\"Continuation to:\")\n",
    "print(\"===================\")\n",
    "print(f\"{prompts[0]}\")\n",
    "print(\"===================\")\n",
    "\n",
    "for i, output in enumerate(decoded_output):\n",
    "    print(f\"Output {i}: {output}\")\n",
    "    results = {}\n",
    "    results['meta'] = {}\n",
    "    results['meta']['previous_text'] = new_record_processed['meta']['previous_text']\n",
    "    results['meta']['gold_text'] = new_record_processed['meta']['gold_text']\n",
    "    results['gen'] = output\n",
    "    scores = evaluate([results], 0)\n",
    "    print(json.dumps(scores, indent=4))\n",
    "    print(f\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    new_record_processed[\"context\"],\n",
    "    new_record_processed[\"context\"],\n",
    "]\n",
    "\n",
    "prompts = [\n",
    "    new_record_processed[\"prompt\"],\n",
    "    f\"{new_record_processed['context_prefix']}\\n\\n{new_record_processed['context']}{new_record_processed['prompt']}\",\n",
    "]\n",
    "\n",
    "\n",
    "max_length = 200\n",
    "decoding_strategy = 'greedy'\n",
    "use_repetition_penalty = True\n",
    "repetition_penalty_value = 1.5\n",
    "k = 10\n",
    "strategy = 'entropy'\n",
    "lamba = 1.0\n",
    "temperature = 1.0\n",
    "variant = \"normal\"\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            prompts=prompts,\n",
    "                            contexts=contexts,\n",
    "                            max_length=max_length,\n",
    "                            decoding_strategy=decoding_strategy,\n",
    "                            k=k,\n",
    "                            strategy=strategy,\n",
    "                            lamba=lamba,\n",
    "                            variant=variant,\n",
    "                            use_repetition_penalty=use_repetition_penalty,\n",
    "                            repetition_penalty_value=repetition_penalty_value,\n",
    "                            datastore_from_layer_index=-1,\n",
    "                            temperature=temperature\n",
    "                            )\n",
    "decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(f\"Continuation to:\")\n",
    "print(\"===================\")\n",
    "print(f\"{prompts[0]}\")\n",
    "print(\"===================\")\n",
    "\n",
    "for i, output in enumerate(decoded_output):\n",
    "    print(f\"Output {i}: {output}\")\n",
    "    results = {}\n",
    "    results['meta'] = {}\n",
    "    results['meta']['previous_text'] = new_record_processed['meta']['previous_text']\n",
    "    results['meta']['gold_text'] = new_record_processed['meta']['gold_text']\n",
    "    results['gen'] = output\n",
    "    scores = evaluate([results], 0)\n",
    "    print(json.dumps(scores, indent=4))\n",
    "    print(f\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    new_record_processed[\"context\"],\n",
    "    new_instructed_record_processed[\"context\"],\n",
    "]\n",
    "\n",
    "prompts = [\n",
    "    new_record_processed[\"prompt\"],\n",
    "    new_instructed_record_processed[\"prompt\"],\n",
    "]\n",
    "\n",
    "\n",
    "max_length = 300\n",
    "decoding_strategy = 'greedy'\n",
    "use_repetition_penalty = True\n",
    "repetition_penalty_value = 1.5\n",
    "k = 10\n",
    "lamba_strategy = 'entropy'\n",
    "lamba = 0.6\n",
    "temperature = 1.0\n",
    "variant = \"normal\"\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            prompts=prompts,\n",
    "                            contexts=contexts,\n",
    "                            max_length=max_length,\n",
    "                            decoding_strategy=decoding_strategy,\n",
    "                            k=k,\n",
    "                            lamba_strategy=lamba_strategy,\n",
    "                            lamba=lamba,\n",
    "                            variant=variant,\n",
    "                            use_repetition_penalty=use_repetition_penalty,\n",
    "                            repetition_penalty_value=repetition_penalty_value,\n",
    "                            datastore_from_layer_index=-1,\n",
    "                            temperature=temperature\n",
    "                            )\n",
    "decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "for i, output in enumerate(decoded_output):\n",
    "    print(f\"Output {i}: {output}\")\n",
    "    results = {}\n",
    "    results['meta'] = {}\n",
    "    results['meta']['previous_text'] = new_record_processed['meta']['previous_text']\n",
    "    results['meta']['gold_text'] = new_record_processed['meta']['gold_text']\n",
    "    results['gen'] = output\n",
    "    scores = evaluate([results], 0)\n",
    "    print(json.dumps(scores, indent=4))\n",
    "    print(f\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts = [[\"Meow\"]]\n",
    "# prompts = ['Say one number and dont say anything else.']\n",
    "\n",
    "prompt_chat = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please answer the question. Do not include additional information.\"},\n",
    "  {\"role\": \"user\", \"content\": \"In one word, what comes after the number one?\"},\n",
    "]\n",
    "\n",
    "prompt = knnlm_model.tokenizer.apply_chat_template(prompt_chat, tokenize=False)\n",
    "print(prompt)\n",
    "contexts = [\n",
    "    [\"Hi.\"]]\n",
    "prompts = [\n",
    "prompt]\n",
    "\n",
    "max_length = 30\n",
    "decoding_strategy = 'greedy'\n",
    "use_repetition_penalty = True\n",
    "repetition_penalty_value = 1.5\n",
    "k = 1\n",
    "lamba_strategy = 'entropy'\n",
    "lamba = 0.5\n",
    "temperature = 1.0\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            prompts=prompts,\n",
    "                            contexts=contexts,\n",
    "                            max_length=max_length,\n",
    "                            decoding_strategy=decoding_strategy,\n",
    "                            k=k,\n",
    "                            lamba_strategy=lamba_strategy,\n",
    "                            lamba=lamba,\n",
    "                            top_p_value=0.9,\n",
    "                            top_k_value=10,\n",
    "                            use_repetition_penalty=use_repetition_penalty,\n",
    "                            repetition_penalty_value=repetition_penalty_value,\n",
    "                            datastore_from_layer_index=-1,\n",
    "                            temperature=temperature\n",
    "                            )\n",
    "decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
    "for i, output in enumerate(decoded_output):\n",
    "    print(f\"Output {i}: {output}\")\n",
    "    # results = {}\n",
    "    # results['meta'] = {}\n",
    "    # results['meta']['previous_text'] = all_documents_record_processed['previous_text']\n",
    "    # results['meta']['gold_text'] = all_documents_record_processed['gold_text']\n",
    "    # results['gen'] = output\n",
    "    # scores = evaluate([results], 0)\n",
    "    # print(json.dumps(scores, indent=4))\n",
    "    # print(f\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# generator = pipeline(model=\"openai-community/gpt2\")\n",
    "# generator(\"I can't believe you did such a \", do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 : Compare w/ or w/o using Context-aware Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts = [\"\"\"\n",
    "# Below are reference cases provided for factual accuracy. When generating content, you must reference and cross-check the relevant details with the provided reference texts by their reference IDs (e.g., 114 F.3d 596, 114 F.3d 596, 114 F.3d 596).\n",
    "\n",
    "# These references take precedence over inferred or assumed information. Your output must clearly align with the facts in these cases.\n",
    "\n",
    "\n",
    "# 114 F.3d 596\n",
    "# Relations Act, 29 U.S.C. § 185. The parties filed cross-motions for summary judgment, and the district court enforced the award. The Beacon Journal filed this timely appeal. II. This court reviews the district court’s grant of summary judgment de novo. Rowley v. United States, 76 F.3d 796, 799 (6th Cir.1996). Nevertheless, our scope of review, like the review of the district court, is extremely limited. The Supreme Court has made clear in the Steelworkers’ Trilogy and its progeny that courts must accord an arbitrator’s decision substantial deference because it is the arbitrator’s construction of the agreement, not the court’s construction, to which the parties have agreed. See United Paperworkers Int’l Union v. Misco, 484 U.S. 29, 37-8, 108 S.Ct. 364, 371, 98 L.Ed.2d 286 (1987) (“Because the parties have contracted to have disputes settled by an arbitrator chosen by them rather than by a judge, it is the arbitrator’s view of the facts and of the meaning of the contract that they have agreed to accept.”). Hence, our review is extremely limited. We review the arbitrator’s decision only to determine whether the arbitrator was “arguably construing or applying the contract and acting within the scope of his authority.” Id. at 38, 108 S.Ct. at 371. If the arbitrator’s award “draws its essence from the collective bargaining agreement,” and is not merely the arbitrator’s “own brand of industrial justice,” the award is legitimate. United Steelworkers of Am. v. Enterprise Wheel & Car Co., 363 U.S. 593, 597, 80 S.Ct. 1358, 1361, 4 L.Ed.2d 1424 (1960). Courts will not weigh the merits of the claim or determine whether the claim is supported by language in the written instrument; otherwise, the policy of settling labor disputes through arbitration would be undermined. Misco, 484 U.S. at 36, 108 S.Ct. at 369-70; see also United\n",
    "\n",
    "# 114 F.3d 596\n",
    "# any evidence that a member had “to modify or change his/her vacation plans due to the management’s ‘new interpretation of its rights under the vacation and management rights clauses of the labor agreement.” Arbitrator’s Decision, Slip op. at 6. In contrast, management was “vague on the specifics of not being able to meet the necessities of the supervisors and the production needs of the newspaper.” Id. The arbitrator made no further findings, but instead found that the Union’s grievance was justified. He then crafted his own solution, whereby the four new supervisors and the Union employees were thrown into a “seniority pool” for vacation selection purposes. He also provided for a grievance procedure through the Union for employees that believed they were adversely affected by the new procedure. The Beacon Journal refused to comply with the arbitration award and instead instituted this lawsuit under section 801 of the Labor Management Relations Act, 29 U.S.C. § 185. The parties filed cross-motions for summary judgment, and the district court enforced the award. The Beacon Journal filed this timely appeal. II. This court reviews the district court’s grant of summary judgment de novo. Rowley v. United States, 76 F.3d 796, 799 (6th Cir.1996). Nevertheless, our scope of review, like the review of the district court, is extremely limited. The Supreme Court has made clear in the Steelworkers’ Trilogy and its progeny that courts must accord an arbitrator’s decision substantial deference because it is the arbitrator’s construction of the agreement, not the court’s construction, to which the parties have agreed. See United Paperworkers Int’l Union v. Misco, 484 U.S. 29, 37-8, 108 S.Ct. 364, 371, 98 L.Ed.2d 286 (1987) (“Because the parties have contracted to have disputes settled by an arbitrator chosen by them rather than by a judge, it is the arbitrator’s view\n",
    "\n",
    "# 114 F.3d 596\n",
    "# of the facts and of the meaning of the contract that they have agreed to accept.”). Hence, our review is extremely limited. We review the arbitrator’s decision only to determine whether the arbitrator was “arguably construing or applying the contract and acting within the scope of his authority.” Id. at 38, 108 S.Ct. at 371. If the arbitrator’s award “draws its essence from the collective bargaining agreement,” and is not merely the arbitrator’s “own brand of industrial justice,” the award is legitimate. United Steelworkers of Am. v. Enterprise Wheel & Car Co., 363 U.S. 593, 597, 80 S.Ct. 1358, 1361, 4 L.Ed.2d 1424 (1960). Courts will not weigh the merits of the claim or determine whether the claim is supported by language in the written instrument; otherwise, the policy of settling labor disputes through arbitration would be undermined. Misco, 484 U.S. at 36, 108 S.Ct. at 369-70; see also United Steelworkers of Am. v. American Mfg. Co., 363 U.S. 564, 568, 80 S.Ct. 1343, 1346, 4 L.Ed.2d 1403 (1960) (“[C]ourts, therefore, have no business weighing the merits of the grievance, considering whether there is equity in a particular claim, or determining whether there is particular language in the written instrument which will support the claim.”). Despite the great amount of deference accorded an arbitrator’s decision, our review is not toothless when an arbitrator’s award disregards the collective bargaining agreement and its terms. See Lattimer-Stevens Co. v. United Steelworkers, 913 F.2d 1166, 1171-72 (6th Cir.1990) (Boggs, J., dissenting) (delineating eases setting aside arbitrator’s decision). Even though arbitrators are not flawless, courts must refrain from reversing an arbitrator simply because the court disagrees with the result or believes the arbitrator made a serious legal or factual error. Misco, 484 U.S. at 38, 108 S.Ct. at 371 (“that a court is convinced [the\n",
    "# \"\"\"]\n",
    "\n",
    "# prompts = [\"\"\"\n",
    "# Continue to write the following case using the style of my write-up. Your response should:\n",
    "# 1. Be concise and within 100 to 400 words.\n",
    "# 2. Explicitly cite the reference IDs in the text where applicable to ensure factual consistency.\n",
    "# 3. Avoid redundant language, assumptions, or information not found in the references.\n",
    "\n",
    "# BEER, District Judge.\n",
    "# Alken-Ziegler, Incorporated, (Company) appeals from the district court’s grant of summary judgment affirming an arbitration award in favor of the International Union, United Automobile, Aerospace and Agricultural Implement Workers of America, and Local Union 985 (Union). For the following reasons, we find that, even in light of our deferential review, the arbitrator disregarded the provisions of the labor contract. Therefore, we reverse the district court’s decision and vacate the arbitration award.\n",
    "# I\n",
    "# The Company and the Union were parties to a labor contract effective December 15, 1999. In March, 2001, the Company notified the Union that it would be closing its Novi plant and that it would be necessary to terminate all of the employees at the facility. As a result of the plant closing on October 17, 2001, all but one employee was terminated during the calendar year, 2001. The Company refused to pay vacationpay benefits to employees who did not work for the Company on January 1, 2002. The Union filed a grievance.\n",
    "# Article 16 (61) of the labor agreement sets forth the eligibility requirement for payment of vacation benefits:\n",
    "# (a) Employees shall be eligible for vacations, time off and vacation pay as set forth below.\n",
    "# (b) For purposes of eligibility, the vacation year will be considered the calendar year period from January 1st to December 31.\n",
    "# (c) An employee covered by the agreement who is actually working on January 1st of any year and who has at least six (6) months seniority and has' worked at least eight hundred (800) hours from and after January 1st of the previous year shall be paid the equivalent of two-and-one half (2-1/2) days vacation pay.\n",
    "# ijs ifc tjc %\n",
    "# (f) Employees with twelve (12) months or more of seniority who have worked more than eight hundred (800) hours, but less than sixteen hundred (1600) hours, during the vacation year, shall receive a pro-rated vacation pay on the basis of the ratio of their actual hours to sixteen hundred (1600) hours, but not to exceed the full vacation pay to which they were entitled by reason of their seniority and hours worked as set forth above.\n",
    "# (g) Vacation pay will be computed on a straight time forty (40) hour basis including applicable shift premium. The employee’s hour basis including applicable shift premium. The employee’s hourly rate in effect when vacation is taken will be used to compute vacation pay. If an employee is laid off after six (6) months service, their vacation pay will be pro-rated same as above.\n",
    "# Pursuant to Article 5 of the labor contract, the parties arbitrated the grievance. At the arbitration the Union asserted that because it was not the employees’ fault that they were unable to work the full year, the employees were entitled to their vacation pay. The arbitrator granted the grievance, allowing all plaintiffs, who, but for being laid off, would have been able to continue employment and thereby qualify for vacation benefits. The arbitrator reasoned that “[i]t would be unreasonable to cause such forfeitures particularly where an employee has no control over the situation.”\n",
    "# The Company filed a complaint in the district court asserting that the arbitrator’s award contradicted the clear, mandatory commands of the labor contract, which required that an employee be “actually working” for the Company as of January 1, 2002, to receive vacation pay. The district court granted the Union’s motion for summary judgment and upheld the arbitrator’s award. The Company appealed.\n",
    "# II\n",
    "# \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_prompt(prev_text, retrieved_docs, retrieved_ids):\n",
    "    ref_text = '\\n\\n'.join(retrieved_docs)\n",
    "    context = (\n",
    "        ref_text \n",
    "    )\n",
    "    prompt = (\n",
    "        'Continue to write the following case using the style of my write up. Your answer contains from 100 to 400 words. Make your answer concise, relevant and avoid redundant language.\\n\\n' +\n",
    "        prev_text\n",
    "    )\n",
    "    return context, prompt\n",
    "\n",
    "record_example = clerc_dataset[\"train\"][0]\n",
    "\n",
    "old_record_processed = preprocess_function(record_example, 3, build_context_prompt)\n",
    "print(json.dumps(old_record_processed, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_context_prompt(prev_text, retrieved_docs, retrieved_ids):\n",
    "#     ref_text = '\\n\\n'.join(retrieved_docs)\n",
    "#     context = (\n",
    "#         ref_text \n",
    "#     )\n",
    "#     prompt = (\n",
    "#         'Continue to write the following case using the style of my write up. Your answer contains from 100 to 400 words. Make your answer concise, relevant and avoid redundant language.\\n\\n' +\n",
    "#         prev_text\n",
    "#     )\n",
    "#     return context, prompt\n",
    "\n",
    "# record_example = clerc_dataset[\"train\"][0]\n",
    "\n",
    "# old_record_processed = preprocess_function(record_example, 3, build_context_prompt)\n",
    "# print(json.dumps(old_record_processed, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from experiments.generation.workshop.experiment_utils_old import preprocess_function, evaluate\n",
    "\n",
    "data_dir = \"bm25_oracle_passages_oracle_documents\"\n",
    "clerc_dataset = load_dataset(\"ylkhayat/CLERC-generation-workshop\", data_dir=data_dir)\n",
    "\n",
    "\n",
    "def build_context_prompt(prev_text, retrieved_docs, retrieved_ids):\n",
    "    ref_text = '\\n\\n'.join(retrieved_docs)\n",
    "    context = (\n",
    "        # \"Below are reference cases provided for factual accuracy. When generating content, you must reference and cross-check the relevant details with the provided reference texts by their reference IDs (e.g., \" + ', '.join(retrieved_ids) + \").\\n\" +\n",
    "        # \"These references take precedence over inferred or assumed information. Your output must clearly align with the facts in these cases.\\n\\n\" +\n",
    "        ref_text\n",
    "    )\n",
    "    prompt = (\n",
    "        \"Continue to write the following case using the style of my write-up. Your response should:\\n1. Be concise and within 100 to 400 words.\\n2. Explicitly cite the reference IDs in the text where applicable to ensure factual consistency.\\n3. Avoid redundant language, assumptions, or information not found in the references.\\n\\n\" +\n",
    "        prev_text\n",
    "    )\n",
    "    return context, prompt\n",
    "\n",
    "record_example_0 = clerc_dataset[\"train\"][0]\n",
    "record_example_0 = preprocess_function(record_example_0, 3, build_context_prompt)\n",
    "print(json.dumps(record_example_0, indent=4))\n",
    "record_example_1 = clerc_dataset[\"train\"][7]\n",
    "record_example_1 = preprocess_function(record_example_1, 3, build_context_prompt)\n",
    "print(json.dumps(record_example_1, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from datasets import load_dataset\n",
    "# from workshop.experiment_utils import preprocess_function, evaluate\n",
    "\n",
    "# data_dir = \"bm25_oracle_passages_oracle_documents\"\n",
    "# clerc_dataset = load_dataset(\"ylkhayat/CLERC-generation-workshop\", data_dir=data_dir)\n",
    "\n",
    "\n",
    "# def build_context_prompt(prev_text, retrieved_docs, retrieved_ids):\n",
    "#     ref_text = '\\n\\n'.join(retrieved_docs)\n",
    "#     context = (\n",
    "#         'Below will be provided some reference cases, which you can use and must mention their reference ids, i.e. ' + ', '.join(retrieved_ids) + '.\\n\\n' +\n",
    "#         ref_text + '\\n\\n'\n",
    "#     )\n",
    "#     prompt = (\n",
    "#         'Continue to write the following case using the style of my write up. Your answer contains from 100 to 400 words. Make your answer concise, relevant and avoid redundant language.\\n\\n' +\n",
    "#         prev_text\n",
    "#     )\n",
    "#     return context, prompt\n",
    "\n",
    "# record_example = clerc_dataset[\"train\"][0]\n",
    "\n",
    "# record_processed = preprocess_function(record_example, 3, build_context_prompt)\n",
    "# contexts = record_processed[\"context\"]\n",
    "# prompts = record_processed[\"prompt\"]\n",
    "# print(json.dumps(record_processed, indent=4))\n",
    "\n",
    "# max_length = 200\n",
    "# decoding_strategy = 'greedy'\n",
    "# use_repetition_penalty = True\n",
    "# repetition_penalty_value = 1.5\n",
    "# k = 10\n",
    "# method = 'knnlm'\n",
    "# lamba_strategy = 'constant'\n",
    "# lamba = 0.5\n",
    "\n",
    "# outputs = knnlm_model.generate(\n",
    "#                             prompts=prompts,\n",
    "#                             contexts=contexts,\n",
    "#                             max_length=max_length,\n",
    "#                             decoding_strategy=decoding_strategy,\n",
    "#                             k=k,\n",
    "#                             lamba_strategy=lamba_strategy,\n",
    "#                             lamba=lamba,\n",
    "#                             use_repetition_penalty=use_repetition_penalty,\n",
    "#                             repetition_penalty_value=repetition_penalty_value,\n",
    "#                             )\n",
    "# decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "# for i, output in enumerate(decoded_output):\n",
    "#     print(f\"Output {i}: {output}\")\n",
    "# results = {}\n",
    "# results['meta'] = {}\n",
    "# results['meta']['previous_text'] = record_processed['previous_text']\n",
    "# results['meta']['gold_text'] = record_processed['gold_text']\n",
    "# results['gen'] = decoded_output[0]\n",
    "# scores = evaluate([results], 0)\n",
    "# print(json.dumps(scores, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from datasets import load_dataset\n",
    "# from workshop.experiment_utils import preprocess_function, evaluate\n",
    "\n",
    "# data_dir = \"bm25_oracle_passages_oracle_documents\"\n",
    "# clerc_dataset = load_dataset(\"ylkhayat/CLERC-generation-workshop\", data_dir=data_dir)\n",
    "\n",
    "\n",
    "# def build_context_prompt(prev_text, retrieved_docs, retrieved_ids):\n",
    "#     ref_text = '\\n'.join(retrieved_docs)\n",
    "#     context = (\n",
    "#         \"Below are reference cases provided for factual accuracy. When generating content, you must reference and cross-check the relevant details with the provided reference texts by their reference IDs (e.g., \" + ', '.join(retrieved_ids) + \").\\n\" +\n",
    "#         \"These references take precedence over inferred or assumed information. Your output must clearly align with the facts in these cases.\\n\\n\" +\n",
    "#         ref_text\n",
    "#     )\n",
    "#     prompt = (\n",
    "#         \"Continue to write the following case using the style of my write-up. Your response should:\\n1. Be concise and within 100 to 400 words.\\n2. Explicitly cite the reference IDs in the text where applicable to ensure factual consistency.\\n3. Avoid redundant language, assumptions, or information not found in the references.\\n\\n\" +\n",
    "#         prev_text\n",
    "#     )\n",
    "#     return context, prompt\n",
    "\n",
    "# record_example = clerc_dataset[\"train\"][0]\n",
    "\n",
    "# record_processed = preprocess_function(record_example, 3, build_context_prompt)\n",
    "# contexts = record_processed[\"context\"]\n",
    "# prompts = record_processed[\"prompt\"]\n",
    "# print(json.dumps(record_processed, indent=4))\n",
    "\n",
    "# max_length = 200\n",
    "# decoding_strategy = 'greedy'\n",
    "# use_repetition_penalty = True\n",
    "# repetition_penalty_value = 1.5\n",
    "# k = 10\n",
    "# method = 'knnlm'\n",
    "# lamba_strategy = 'constant'\n",
    "# lamba = 0.5\n",
    "\n",
    "# outputs = knnlm_model.generate(\n",
    "#                             prompts=prompts,\n",
    "#                             contexts=contexts,\n",
    "#                             max_length=max_length,\n",
    "#                             decoding_strategy=decoding_strategy,\n",
    "#                             k=k,\n",
    "#                             lamba_strategy=lamba_strategy,\n",
    "#                             lamba=lamba,\n",
    "#                             use_repetition_penalty=use_repetition_penalty,\n",
    "#                             repetition_penalty_value=repetition_penalty_value,\n",
    "#                             )\n",
    "# decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "# for i, output in enumerate(decoded_output):\n",
    "#     print(f\"Output {i}: {output}\")\n",
    "# results = {}\n",
    "# results['meta'] = {}\n",
    "# results['meta']['previous_text'] = record_processed['previous_text']\n",
    "# results['meta']['gold_text'] = record_processed['gold_text']\n",
    "# results['gen'] = decoded_output[0]\n",
    "# scores = evaluate([results], 0)\n",
    "# print(json.dumps(scores, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts = [\n",
    "#     # Old context\n",
    "#     \"\"\"\n",
    "#     Below will be provided some reference cases, which you can use and must mention their reference ids, i.e. 114 F.3d 596, 114 F.3d 596, 114 F.3d 596.\n",
    "    \n",
    "#     114 F.3d 596\n",
    "#     Relations Act, 29 U.S.C. \\u00a7 185. The parties filed cross-motions for summary judgment, and the district court enforced the award. The Beacon Journal filed this timely appeal. II. This court reviews the district court\\u2019s grant of summary judgment de novo. Rowley v. United States, 76 F.3d 796, 799 (6th Cir.1996). Nevertheless, our scope of review, like the review of the district court, is extremely limited. The Supreme Court has made clear in the Steelworkers\\u2019 Trilogy and its progeny that courts must accord an arbitrator\\u2019s decision substantial deference because it is the arbitrator\\u2019s construction of the agreement, not the court\\u2019s construction, to which the parties have agreed. See United Paperworkers Int\\u2019l Union v. Misco, 484 U.S. 29, 37-8, 108 S.Ct. 364, 371, 98 L.Ed.2d 286 (1987) (\\u201cBecause the parties have contracted to have disputes settled by an arbitrator chosen by them rather than by a judge, it is the arbitrator\\u2019s view of the facts and of the meaning of the contract that they have agreed to accept.\\u201d). Hence, our review is extremely limited. We review the arbitrator\\u2019s decision only to determine whether the arbitrator was \\u201carguably construing or applying the contract and acting within the scope of his authority.\\u201d Id. at 38, 108 S.Ct. at 371. If the arbitrator\\u2019s award \\u201cdraws its essence from the collective bargaining agreement,\\u201d and is not merely the arbitrator\\u2019s \\u201cown brand of industrial justice,\\u201d the award is legitimate. United Steelworkers of Am. v. Enterprise Wheel & Car Co., 363 U.S. 593, 597, 80 S.Ct. 1358, 1361, 4 L.Ed.2d 1424 (1960). Courts will not weigh the merits of the claim or determine whether the claim is supported by language in the written instrument; otherwise, the policy of settling labor disputes through arbitration would be undermined. Misco, 484 U.S. at 36, 108 S.Ct. at 369-70; see also United\n",
    "    \n",
    "#     114 F.3d 596\n",
    "#     any evidence that a member had \\u201cto modify or change his/her vacation plans due to the management\\u2019s \\u2018new interpretation of its rights under the vacation and management rights clauses of the labor agreement.\\u201d Arbitrator\\u2019s Decision, Slip op. at 6. In contrast, management was \\u201cvague on the specifics of not being able to meet the necessities of the supervisors and the production needs of the newspaper.\\u201d Id. The arbitrator made no further findings, but instead found that the Union\\u2019s grievance was justified. He then crafted his own solution, whereby the four new supervisors and the Union employees were thrown into a \\u201cseniority pool\\u201d for vacation selection purposes. He also provided for a grievance procedure through the Union for employees that believed they were adversely affected by the new procedure. The Beacon Journal refused to comply with the arbitration award and instead instituted this lawsuit under section 801 of the Labor Management Relations Act, 29 U.S.C. \\u00a7 185. The parties filed cross-motions for summary judgment, and the district court enforced the award. The Beacon Journal filed this timely appeal. II. This court reviews the district court\\u2019s grant of summary judgment de novo. Rowley v. United States, 76 F.3d 796, 799 (6th Cir.1996). Nevertheless, our scope of review, like the review of the district court, is extremely limited. The Supreme Court has made clear in the Steelworkers\\u2019 Trilogy and its progeny that courts must accord an arbitrator\\u2019s decision substantial deference because it is the arbitrator\\u2019s construction of the agreement, not the court\\u2019s construction, to which the parties have agreed. See United Paperworkers Int\\u2019l Union v. Misco, 484 U.S. 29, 37-8, 108 S.Ct. 364, 371, 98 L.Ed.2d 286 (1987) (\\u201cBecause the parties have contracted to have disputes settled by an arbitrator chosen by them rather than by a judge, it is the arbitrator\\u2019s view\n",
    "    \n",
    "#     114 F.3d 596\n",
    "#     of the facts and of the meaning of the contract that they have agreed to accept.\\u201d). Hence, our review is extremely limited. We review the arbitrator\\u2019s decision only to determine whether the arbitrator was \\u201carguably construing or applying the contract and acting within the scope of his authority.\\u201d Id. at 38, 108 S.Ct. at 371. If the arbitrator\\u2019s award \\u201cdraws its essence from the collective bargaining agreement,\\u201d and is not merely the arbitrator\\u2019s \\u201cown brand of industrial justice,\\u201d the award is legitimate. United Steelworkers of Am. v. Enterprise Wheel & Car Co., 363 U.S. 593, 597, 80 S.Ct. 1358, 1361, 4 L.Ed.2d 1424 (1960). Courts will not weigh the merits of the claim or determine whether the claim is supported by language in the written instrument; otherwise, the policy of settling labor disputes through arbitration would be undermined. Misco, 484 U.S. at 36, 108 S.Ct. at 369-70; see also United Steelworkers of Am. v. American Mfg. Co., 363 U.S. 564, 568, 80 S.Ct. 1343, 1346, 4 L.Ed.2d 1403 (1960) (\\u201c[C]ourts, therefore, have no business weighing the merits of the grievance, considering whether there is equity in a particular claim, or determining whether there is particular language in the written instrument which will support the claim.\\u201d). Despite the great amount of deference accorded an arbitrator\\u2019s decision, our review is not toothless when an arbitrator\\u2019s award disregards the collective bargaining agreement and its terms. See Lattimer-Stevens Co. v. United Steelworkers, 913 F.2d 1166, 1171-72 (6th Cir.1990) (Boggs, J., dissenting) (delineating eases setting aside arbitrator\\u2019s decision). Even though arbitrators are not flawless, courts must refrain from reversing an arbitrator simply because the court disagrees with the result or believes the arbitrator made a serious legal or factual error. Misco, 484 U.S. at 38, 108 S.Ct. at 371 (\\u201cthat a court is convinced [the\n",
    "#     \"\"\",\n",
    "#     # New context\n",
    "#     \"\"\"\n",
    "#     Below are reference cases provided for factual accuracy. When generating content, you must reference and cross-check the relevant details with the provided reference texts by their reference IDs (e.g., 114 F.3d 596, 114 F.3d 596, 114 F.3d 596).\n",
    "    \n",
    "#     These references take precedence over inferred or assumed information. Your output must clearly align with the facts in these cases.\n",
    "    \n",
    "#     114 F.3d 596\n",
    "#     Relations Act, 29 U.S.C. \\u00a7 185. The parties filed cross-motions for summary judgment, and the district court enforced the award. The Beacon Journal filed this timely appeal. II. This court reviews the district court\\u2019s grant of summary judgment de novo. Rowley v. United States, 76 F.3d 796, 799 (6th Cir.1996). Nevertheless, our scope of review, like the review of the district court, is extremely limited. The Supreme Court has made clear in the Steelworkers\\u2019 Trilogy and its progeny that courts must accord an arbitrator\\u2019s decision substantial deference because it is the arbitrator\\u2019s construction of the agreement, not the court\\u2019s construction, to which the parties have agreed. See United Paperworkers Int\\u2019l Union v. Misco, 484 U.S. 29, 37-8, 108 S.Ct. 364, 371, 98 L.Ed.2d 286 (1987) (\\u201cBecause the parties have contracted to have disputes settled by an arbitrator chosen by them rather than by a judge, it is the arbitrator\\u2019s view of the facts and of the meaning of the contract that they have agreed to accept.\\u201d). Hence, our review is extremely limited. We review the arbitrator\\u2019s decision only to determine whether the arbitrator was \\u201carguably construing or applying the contract and acting within the scope of his authority.\\u201d Id. at 38, 108 S.Ct. at 371. If the arbitrator\\u2019s award \\u201cdraws its essence from the collective bargaining agreement,\\u201d and is not merely the arbitrator\\u2019s \\u201cown brand of industrial justice,\\u201d the award is legitimate. United Steelworkers of Am. v. Enterprise Wheel & Car Co., 363 U.S. 593, 597, 80 S.Ct. 1358, 1361, 4 L.Ed.2d 1424 (1960). Courts will not weigh the merits of the claim or determine whether the claim is supported by language in the written instrument; otherwise, the policy of settling labor disputes through arbitration would be undermined. Misco, 484 U.S. at 36, 108 S.Ct. at 369-70; see also United\n",
    "    \n",
    "#     114 F.3d 596\n",
    "#     any evidence that a member had \\u201cto modify or change his/her vacation plans due to the management\\u2019s \\u2018new interpretation of its rights under the vacation and management rights clauses of the labor agreement.\\u201d Arbitrator\\u2019s Decision, Slip op. at 6. In contrast, management was \\u201cvague on the specifics of not being able to meet the necessities of the supervisors and the production needs of the newspaper.\\u201d Id. The arbitrator made no further findings, but instead found that the Union\\u2019s grievance was justified. He then crafted his own solution, whereby the four new supervisors and the Union employees were thrown into a \\u201cseniority pool\\u201d for vacation selection purposes. He also provided for a grievance procedure through the Union for employees that believed they were adversely affected by the new procedure. The Beacon Journal refused to comply with the arbitration award and instead instituted this lawsuit under section 801 of the Labor Management Relations Act, 29 U.S.C. \\u00a7 185. The parties filed cross-motions for summary judgment, and the district court enforced the award. The Beacon Journal filed this timely appeal. II. This court reviews the district court\\u2019s grant of summary judgment de novo. Rowley v. United States, 76 F.3d 796, 799 (6th Cir.1996). Nevertheless, our scope of review, like the review of the district court, is extremely limited. The Supreme Court has made clear in the Steelworkers\\u2019 Trilogy and its progeny that courts must accord an arbitrator\\u2019s decision substantial deference because it is the arbitrator\\u2019s construction of the agreement, not the court\\u2019s construction, to which the parties have agreed. See United Paperworkers Int\\u2019l Union v. Misco, 484 U.S. 29, 37-8, 108 S.Ct. 364, 371, 98 L.Ed.2d 286 (1987) (\\u201cBecause the parties have contracted to have disputes settled by an arbitrator chosen by them rather than by a judge, it is the arbitrator\\u2019s view\n",
    "    \n",
    "#     114 F.3d 596\n",
    "#     of the facts and of the meaning of the contract that they have agreed to accept.\\u201d). Hence, our review is extremely limited. We review the arbitrator\\u2019s decision only to determine whether the arbitrator was \\u201carguably construing or applying the contract and acting within the scope of his authority.\\u201d Id. at 38, 108 S.Ct. at 371. If the arbitrator\\u2019s award \\u201cdraws its essence from the collective bargaining agreement,\\u201d and is not merely the arbitrator\\u2019s \\u201cown brand of industrial justice,\\u201d the award is legitimate. United Steelworkers of Am. v. Enterprise Wheel & Car Co., 363 U.S. 593, 597, 80 S.Ct. 1358, 1361, 4 L.Ed.2d 1424 (1960). Courts will not weigh the merits of the claim or determine whether the claim is supported by language in the written instrument; otherwise, the policy of settling labor disputes through arbitration would be undermined. Misco, 484 U.S. at 36, 108 S.Ct. at 369-70; see also United Steelworkers of Am. v. American Mfg. Co., 363 U.S. 564, 568, 80 S.Ct. 1343, 1346, 4 L.Ed.2d 1403 (1960) (\\u201c[C]ourts, therefore, have no business weighing the merits of the grievance, considering whether there is equity in a particular claim, or determining whether there is particular language in the written instrument which will support the claim.\\u201d). Despite the great amount of deference accorded an arbitrator\\u2019s decision, our review is not toothless when an arbitrator\\u2019s award disregards the collective bargaining agreement and its terms. See Lattimer-Stevens Co. v. United Steelworkers, 913 F.2d 1166, 1171-72 (6th Cir.1990) (Boggs, J., dissenting) (delineating eases setting aside arbitrator\\u2019s decision). Even though arbitrators are not flawless, courts must refrain from reversing an arbitrator simply because the court disagrees with the result or believes the arbitrator made a serious legal or factual error. Misco, 484 U.S. at 38, 108 S.Ct. at 371 (\\u201cthat a court is convinced [the\n",
    "#     \"\"\"\n",
    "#     ]\n",
    "\n",
    "# prompts = [\n",
    "#     # Old prompt\n",
    "#     \"\"\"\n",
    "#     Continue to write the following case using the style of my write up. Your answer contains from 100 to 400 words. Make your answer concise, relevant and avoid redundant language.\n",
    "    \n",
    "#     BEER, District Judge.\n",
    "#     Alken-Ziegler, Incorporated, (Company) appeals from the district court\\u2019s grant of summary judgment affirming an arbitration award in favor of the International Union, United Automobile, Aerospace and Agricultural Implement Workers of America, and Local Union 985 (Union). For the following reasons, we find that, even in light of our deferential review, the arbitrator disregarded the provisions of the labor contract. Therefore, we reverse the district court\\u2019s decision and vacate the arbitration award.\n",
    "#     I\n",
    "#     The Company and the Union were parties to a labor contract effective December 15, 1999. In March, 2001, the Company notified the Union that it would be closing its Novi plant and that it would be necessary to terminate all of the employees at the facility. As a result of the plant closing on October 17, 2001, all but one employee was terminated during the calendar year, 2001. The Company refused to pay vacationpay benefits to employees who did not work for the Company on January 1, 2002. The Union filed a grievance.\n",
    "#     Article 16 (61) of the labor agreement sets forth the eligibility requirement for payment of vacation benefits:\n",
    "#     (a) Employees shall be eligible for vacations, time off and vacation pay as set forth below.\n",
    "#     (b) For purposes of eligibility, the vacation year will be considered the calendar year period from January 1st to December 31.\n",
    "#     (c) An employee covered by the agreement who is actually working on January 1st of any year and who has at least six (6) months seniority and has' worked at least eight hundred (800) hours from and after January 1st of the previous year shall be paid the equivalent of two-and-one half (2-1/2) days vacation pay.\n",
    "#     ijs ifc tjc %\n",
    "#     (f) Employees with twelve (12) months or more of seniority who have worked more than eight hundred (800) hours, but less than sixteen hundred (1600) hours, during the vacation year, shall receive a pro-rated vacation pay on the basis of the ratio of their actual hours to sixteen hundred (1600) hours, but not to exceed the full vacation pay to which they were entitled by reason of their seniority and hours worked as set forth above.\n",
    "#     (g) Vacation pay will be computed on a straight time forty (40) hour basis including applicable shift premium. The employee\\u2019s hour basis including applicable shift premium. The employee\\u2019s hourly rate in effect when vacation is taken will be used to compute vacation pay. If an employee is laid off after six (6) months service, their vacation pay will be pro-rated same as above.\n",
    "#     Pursuant to Article 5 of the labor contract, the parties arbitrated the grievance. At the arbitration the Union asserted that because it was not the employees\\u2019 fault that they were unable to work the full year, the employees were entitled to their vacation pay. The arbitrator granted the grievance, allowing all plaintiffs, who, but for being laid off, would have been able to continue employment and thereby qualify for vacation benefits. The arbitrator reasoned that \\u201c[i]t would be unreasonable to cause such forfeitures particularly where an employee has no control over the situation.\\u201d\n",
    "#     The Company filed a complaint in the district court asserting that the arbitrator\\u2019s award contradicted the clear, mandatory commands of the labor contract, which required that an employee be \\u201cactually working\\u201d for the Company as of January 1, 2002, to receive vacation pay. The district court granted the Union\\u2019s motion for summary judgment and upheld the arbitrator\\u2019s award. The Company appealed.\n",
    "#     II\n",
    "#     \"\"\",\n",
    "#     # New prompt\n",
    "#     \"\"\"\n",
    "#     Continue to write the following case using the style of my write-up. \n",
    "#     Your response should:\n",
    "#     - Be concise and within 100 to 400 words.\n",
    "#     - Explicitly cite the reference IDs in the text where applicable to ensure factual consistency.\n",
    "#     - Avoid redundant language, assumptions, or information not found in the references.\n",
    "    \n",
    "#     BEER, District Judge.\n",
    "#     Alken-Ziegler, Incorporated, (Company) appeals from the district court\\u2019s grant of summary judgment affirming an arbitration award in favor of the International Union, United Automobile, Aerospace and Agricultural Implement Workers of America, and Local Union 985 (Union). For the following reasons, we find that, even in light of our deferential review, the arbitrator disregarded the provisions of the labor contract. Therefore, we reverse the district court\\u2019s decision and vacate the arbitration award.\n",
    "#     I\n",
    "#     The Company and the Union were parties to a labor contract effective December 15, 1999. In March, 2001, the Company notified the Union that it would be closing its Novi plant and that it would be necessary to terminate all of the employees at the facility. As a result of the plant closing on October 17, 2001, all but one employee was terminated during the calendar year, 2001. The Company refused to pay vacationpay benefits to employees who did not work for the Company on January 1, 2002. The Union filed a grievance.\n",
    "#     Article 16 (61) of the labor agreement sets forth the eligibility requirement for payment of vacation benefits:\n",
    "#     (a) Employees shall be eligible for vacations, time off and vacation pay as set forth below.\n",
    "#     (b) For purposes of eligibility, the vacation year will be considered the calendar year period from January 1st to December 31.\n",
    "#     (c) An employee covered by the agreement who is actually working on January 1st of any year and who has at least six (6) months seniority and has' worked at least eight hundred (800) hours from and after January 1st of the previous year shall be paid the equivalent of two-and-one half (2-1/2) days vacation pay.\n",
    "#     ijs ifc tjc %\n",
    "#     (f) Employees with twelve (12) months or more of seniority who have worked more than eight hundred (800) hours, but less than sixteen hundred (1600) hours, during the vacation year, shall receive a pro-rated vacation pay on the basis of the ratio of their actual hours to sixteen hundred (1600) hours, but not to exceed the full vacation pay to which they were entitled by reason of their seniority and hours worked as set forth above.\n",
    "#     (g) Vacation pay will be computed on a straight time forty (40) hour basis including applicable shift premium. The employee\\u2019s hour basis including applicable shift premium. The employee\\u2019s hourly rate in effect when vacation is taken will be used to compute vacation pay. If an employee is laid off after six (6) months service, their vacation pay will be pro-rated same as above.\n",
    "#     Pursuant to Article 5 of the labor contract, the parties arbitrated the grievance. At the arbitration the Union asserted that because it was not the employees\\u2019 fault that they were unable to work the full year, the employees were entitled to their vacation pay. The arbitrator granted the grievance, allowing all plaintiffs, who, but for being laid off, would have been able to continue employment and thereby qualify for vacation benefits. The arbitrator reasoned that \\u201c[i]t would be unreasonable to cause such forfeitures particularly where an employee has no control over the situation.\\u201d\n",
    "#     The Company filed a complaint in the district court asserting that the arbitrator\\u2019s award contradicted the clear, mandatory commands of the labor contract, which required that an employee be \\u201cactually working\\u201d for the Company as of January 1, 2002, to receive vacation pay. The district court granted the Union\\u2019s motion for summary judgment and upheld the arbitrator\\u2019s award. The Company appealed.\n",
    "#     II\n",
    "#     \"\"\"\n",
    "#     ]\n",
    "\n",
    "# max_length = 200\n",
    "# decoding_strategy = 'greedy'\n",
    "# use_repetition_penalty = True\n",
    "# repetition_penalty_value = 1.5\n",
    "# k = 10\n",
    "# method = 'knnlm'\n",
    "# lamba_strategy = 'constant'\n",
    "# lamba = 0.5\n",
    "\n",
    "# outputs = knnlm_model.generate(\n",
    "#                             prompts=prompts,\n",
    "#                             contexts=contexts,\n",
    "#                             max_length=max_length,\n",
    "#                             decoding_strategy=decoding_strategy,\n",
    "#                             k=k,\n",
    "#                             lamba_strategy=lamba_strategy,\n",
    "#                             lamba=lamba,\n",
    "#                             use_repetition_penalty=use_repetition_penalty,\n",
    "#                             repetition_penalty_value=repetition_penalty_value,\n",
    "#                             )\n",
    "# decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "# for i, output in enumerate(decoded_output):\n",
    "#     print(f\"Output {i}: {output}\")\n",
    "#     results = {}\n",
    "#     results['meta'] = {}\n",
    "#     results['meta']['previous_text'] = new_record_processed['previous_text']\n",
    "#     results['meta']['gold_text'] = new_record_processed['gold_text']\n",
    "#     results['gen'] = output\n",
    "#     scores = evaluate([results], 0)\n",
    "#     print(json.dumps(scores, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(record_example_1, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    # old_record_processed[\"context\"],\n",
    "    record_example_0[\"context\"],\n",
    "    record_example_1[\"context\"]\n",
    "]\n",
    "\n",
    "prompts = [\n",
    "    # old_record_processed[\"prompt\"],\n",
    "    record_example_0[\"prompt\"],\n",
    "    record_example_1[\"prompt\"]\n",
    "]\n",
    "\n",
    "\n",
    "max_length = 250\n",
    "decoding_strategy = 'greedy'\n",
    "use_repetition_penalty = True\n",
    "repetition_penalty_value = 1.5\n",
    "k = 10\n",
    "method = 'knnlm'\n",
    "lamba_strategy = 'entropy'\n",
    "lamba = 0.5\n",
    "temperature = 1.0\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            prompts=prompts,\n",
    "                            contexts=contexts,\n",
    "                            max_length=max_length,\n",
    "                            decoding_strategy=decoding_strategy,\n",
    "                            k=k,\n",
    "                            lamba_strategy=lamba_strategy,\n",
    "                            lamba=lamba,\n",
    "                            use_repetition_penalty=use_repetition_penalty,\n",
    "                            repetition_penalty_value=repetition_penalty_value,\n",
    "                            datastore_from_layer_index=-1,\n",
    "                            temperature=temperature\n",
    "                            )\n",
    "decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "for i, output in enumerate(decoded_output):\n",
    "    print(f\"Output {i}: {output}\")\n",
    "    results = {}\n",
    "    results['meta'] = {}\n",
    "    results['meta']['previous_text'] = old_record_processed['previous_text']\n",
    "    results['meta']['gold_text'] = old_record_processed['gold_text']\n",
    "    results['gen'] = output\n",
    "    scores = evaluate([results], 0)\n",
    "    print(json.dumps(scores, indent=4))\n",
    "    print(f\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rep_extension = f'_rep_{f\"{use_repetition_penalty}_rep_value_{repetition_penalty_value}\" if use_repetition_penalty else use_repetition_penalty}'\n",
    "# filename = f\"../basement/cad_generations/output_{method}_{decoding_strategy}_rep_{rep_extension}_{max_length}.txt\"\n",
    "# os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "# with open(filename, 'w') as file:\n",
    "#     file.write(\"Prompt:\\n\")\n",
    "#     file.write(prompts[0])\n",
    "#     file.write(\"\\n\\nContext:\\n\")\n",
    "#     file.write(contexts[0])\n",
    "#     file.write(\"\\n\\nAnswer:\\n\")\n",
    "#     file.write(knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = range(6)\n",
    "top_k = 4\n",
    "temperature = 1.0\n",
    "\n",
    "indices = [0, 0, 0, 4]\n",
    "distances = np.array([222.21, 222.22, 223.5, 222])\n",
    "\n",
    "logits = - distances / temperature\n",
    "\n",
    "knn_logits = np.zeros(len(vocab))\n",
    "count = np.zeros(len(vocab))\n",
    "for l in range(top_k):\n",
    "    token_id = indices[l]\n",
    "    knn_logits[token_id] += logits[l]\n",
    "    count[token_id] += 1\n",
    "\n",
    "knn_logits = np.divide(knn_logits, count, out=np.zeros_like(knn_logits), where=count != 0)\n",
    "knn_logits[knn_logits == 0.0] = -np.inf\n",
    "print(knn_logits)\n",
    "probs = F.softmax(torch.tensor(knn_logits, dtype=torch.float16))\n",
    "probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "decoding_strategy = 'greedy'\n",
    "use_repetition_penalty = True\n",
    "repetition_penalty_value = 1.2\n",
    "k = 10\n",
    "method = 'knnlm'\n",
    "lamba_strategy = 'constant'\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            input_texts=prompts,\n",
    "                            contexts=contexts,\n",
    "                            max_length=max_length,\n",
    "                            decoding_strategy=decoding_strategy,\n",
    "                            k=k,\n",
    "                            lamba_strategy=lamba_strategy,\n",
    "                            lamba=0.5,\n",
    "                            use_repetition_penalty=use_repetition_penalty,\n",
    "                            repetition_penalty_value=repetition_penalty_value,\n",
    "                            )\n",
    "print(knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])\n",
    "\n",
    "rep_extension = f'_rep_{f\"{use_repetition_penalty}_rep_value_{repetition_penalty_value}\" if use_repetition_penalty else use_repetition_penalty}'\n",
    "filename = f\"../basement/cad_generations/output_{method}_{decoding_strategy}_rep_{rep_extension}_{max_length}.txt\"\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(\"Prompt:\\n\")\n",
    "    file.write(prompts[0])\n",
    "    file.write(\"\\n\\nContext:\\n\")\n",
    "    file.write(contexts[0])\n",
    "    file.write(\"\\n\\nAnswer:\\n\")\n",
    "    file.write(knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])\n",
    "    \n",
    "decoded_output = knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "for i, output in enumerate(decoded_output):\n",
    "    print(f\"Output {i}: {output}\")\n",
    "for i in outputs[0]:\n",
    "    print(f'Token ID : {i} | Token: {knnlm_model.tokenizer.decode(i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Compare w/ or w/o using Repetition Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = ['Write a quote that ends in the word \"early\":']\n",
    "input_texts = ['Better late than']\n",
    "\n",
    "for bool in [True, False]:\n",
    "    outputs = knnlm_model.generate(\n",
    "                                input_texts=input_texts,\n",
    "                                use_context_aware=True,\n",
    "                                contexts=contexts,\n",
    "                                max_length=50,\n",
    "                                alpha=0.5,\n",
    "                                decoding_strategy='greedy',\n",
    "                                top_p_value=0.9,\n",
    "                                use_repetition_penalty=bool,\n",
    "                                repetition_penalty_value=1.5,\n",
    "                                )\n",
    "    print(f\"Repetition Penalty : {bool}\")\n",
    "    print(knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 : alpha value ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in [-0.5, 0.5, 1, 3, 9]:\n",
    "    outputs = knnlm_model.generate(\n",
    "                                input_texts=input_texts,\n",
    "                                use_context_aware=True,\n",
    "                                contexts=contexts,\n",
    "                                max_length=20,\n",
    "                                alpha=alpha,\n",
    "                                decoding_strategy='top_p',\n",
    "                                top_p_value=0.9,\n",
    "                                use_repetition_penalty=True,\n",
    "                                repetition_penalty_value=1.5,\n",
    "                                )\n",
    "\n",
    "    print(f'alpha : {alpha} | {knnlm_model.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = ['Write a quote that ends in the word \"early\":', 'Translate the following sentence into English:']\n",
    "input_texts = ['Better late than', 'Je suis un homme']\n",
    "\n",
    "outputs = knnlm_model.generate(\n",
    "                            input_texts=input_texts,\n",
    "                            use_context_aware=True,\n",
    "                            contexts=contexts,\n",
    "                            max_length=20,\n",
    "                            alpha=0.5,\n",
    "                            decoding_strategy='top_p',\n",
    "                            top_p_value=0.9,\n",
    "                            use_repetition_penalty=True,\n",
    "                            repetition_penalty_value=1.5,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnlm_model.tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in outputs[0]:\n",
    "    print(f'Token ID : {i} | Token: {knnlm_model.tokenizer.decode(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in outputs[1]:\n",
    "    print(f'Token ID : {i} | Token: {knnlm_model.tokenizer.decode(i)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
