{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_original = load_dataset(\"theatticusproject/cuad-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "import re\n",
    "from datasets import DatasetDict\n",
    "import os\n",
    "\n",
    "num_proc=os.cpu_count()\n",
    "\n",
    "from more_itertools import windowed\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def chunk_document(document):\n",
    "#     doc = nlp(document)\n",
    "#     sentences = [sent.text for sent in doc.sents]\n",
    "#     return sentences\n",
    "\n",
    "def process_record(record):\n",
    "    document_id = \"REFERENCE\"\n",
    "    document = record['context']\n",
    "    document = re.sub(r'\\n+', '\\n', document)\n",
    "    answers = record['answers']\n",
    "    answers = record['answers']\n",
    "    if len(answers['text']) > 0:\n",
    "        gold_text = \"Highlights:\\n\" + \"\\n\".join([f\"- {answer}\" for answer in answers['text']])\n",
    "    else:\n",
    "        gold_text = \"No relevant information found in the document.\"\n",
    "    citations = [[document_id, document]]\n",
    "    # sentences = chunk_document(document)\n",
    "    # oracle_documents_passages = []\n",
    "    # # max limit of chunk - tells us number of words, fill in the sentences until max is reached\n",
    "    # for sentence in windowed(sentences, 5, fillvalue=\"\", step=2):\n",
    "    #     section = \" \".join([s for s in sentence if (s is not None and len(s.strip()) > 0)])\n",
    "    #     oracle_documents_passages.append([document_id, section])\n",
    "    \n",
    "    return {\n",
    "        'docid': str(record['id']),\n",
    "        'previous_text': record['question'],\n",
    "        'gold_text': gold_text,\n",
    "        'citations': citations,\n",
    "        # 'oracle_documents_passages': oracle_documents_passages,\n",
    "    }\n",
    "\n",
    "dataset_train = dataset_original['train'].select(range(1000))\n",
    "dataset_test = dataset_original['test']\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'test': dataset_test,\n",
    "})\n",
    "dataset = dataset.map(process_record, num_proc=num_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3688a00b8a8a4f368f201ed958bba654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac96f843701c485f876d1111bb5f09aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8d81d72a6b466487b160f172f0a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124e434ba0f14703bbd0944a67c56595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ylkhayat/CUAD-generation-workshop/commit/af8243ba9fd5967110189c24dcdb8e1e30036142', commit_message='Upload dataset', commit_description='', oid='af8243ba9fd5967110189c24dcdb8e1e30036142', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ylkhayat/CUAD-generation-workshop', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ylkhayat/CUAD-generation-workshop'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.select_columns(['docid', 'previous_text', 'gold_text', 'citations'])\n",
    "dataset.push_to_hub('ylkhayat/CUAD-generation-workshop', data_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - complete documents\n",
    "# text is extracted from context\n",
    "\n",
    "# - align score (gen and the answer) correctness\n",
    "#  ( gen and top k) faithfulness\n",
    " \n",
    "#  - we need to break the context into chunks (paragraphs) - normal spacy -> to get sentences and then put in paragraph \n",
    " \n",
    " \n",
    " \n",
    "#  - instruct to mention no answer explicitly (challenge)\n",
    " \n",
    "#  - challenge correctness (for no answer, manually state that there is no answer for better scores)\n",
    "#  - challenge faithfulness (exclude no answers OR base don generations (if exists evaluate faithfulness, otherwise exclude the record))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
